{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squad404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, VGG16\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Loading the augmented images and converting to pd dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv and images \n",
    "data_annotations_csv = 'augmented_images/image_labels.csv'\n",
    "augmented_images = 'augmented_images'\n",
    "\n",
    "data_file = pd.read_csv(data_annotations_csv, dtype={'label': str})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating vectors of filenames and labels matched by index \n",
    "img_filenames_vector = data_file['filename'].values\n",
    "labels_vector = data_file['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our model\n",
    "\n",
    "Add prototypical network to our model before running it through the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a model from the pretrained CNN base you pass in\n",
    "# Example usage: model = create_model(MobileNetv2)\n",
    "def create_model(base):\n",
    "    base_model = base(input_shape=(224, 224, 3), include_top=False)\n",
    "    base_model.trainable = False # Freeze the base_model\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [ 0  2  3  4  5  6  7  8 10 11 12 13 14 15 17 19 20 22 23 24 25 26 27 28\n",
      " 29 30 31 32 33 34 35 36 37 38 39 41 42 43 44 45 46 47 50 51 53 54 55 56\n",
      " 57 58 59 60 62 63 66 67 69 70 71 72 74 75 76 77 79 80 82 83 85 86 87 88\n",
      " 90 92 94 95], val: [ 1  9 16 18 21 40 48 49 52 61 64 65 68 73 78 81 84 89 91 93]\n",
      "train: [ 1  2  3  4  6  7  9 10 12 13 16 17 18 19 20 21 23 24 26 27 30 33 34 35\n",
      " 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 58 59 60\n",
      " 61 63 64 65 66 68 69 70 71 72 73 74 75 76 77 78 79 80 81 84 85 86 87 88\n",
      " 89 91 92 93 95], val: [ 0  5  8 11 14 15 22 25 28 29 31 32 57 62 67 82 83 90 94]\n",
      "train: [ 0  1  2  3  4  5  7  8  9 10 11 13 14 15 16 18 19 21 22 23 24 25 26 27\n",
      " 28 29 30 31 32 35 36 39 40 41 43 46 47 48 49 50 51 52 53 55 56 57 58 59\n",
      " 61 62 63 64 65 66 67 68 70 72 73 74 75 76 77 78 79 80 81 82 83 84 85 89\n",
      " 90 91 93 94 95], val: [ 6 12 17 20 33 34 37 38 42 44 45 54 60 69 71 86 87 88 92]\n",
      "train: [ 0  1  5  6  7  8  9 10 11 12 13 14 15 16 17 18 20 21 22 23 24 25 28 29\n",
      " 30 31 32 33 34 35 36 37 38 39 40 42 44 45 48 49 51 52 53 54 55 56 57 58\n",
      " 60 61 62 64 65 67 68 69 70 71 73 77 78 79 80 81 82 83 84 85 86 87 88 89\n",
      " 90 91 92 93 94], val: [ 2  3  4 19 26 27 41 43 46 47 50 59 63 66 72 74 75 76 95]\n",
      "train: [ 0  1  2  3  4  5  6  8  9 11 12 14 15 16 17 18 19 20 21 22 25 26 27 28\n",
      " 29 31 32 33 34 37 38 40 41 42 43 44 45 46 47 48 49 50 52 54 57 59 60 61\n",
      " 62 63 64 65 66 67 68 69 71 72 73 74 75 76 78 81 82 83 84 86 87 88 89 90\n",
      " 91 92 93 94 95], val: [ 7 10 13 23 24 30 35 36 39 51 53 55 56 58 70 77 79 80 85]\n"
     ]
    }
   ],
   "source": [
    "for train_index, val_index in kf.split(img_filenames_vector, labels_vector):\n",
    "    print(f\"train: {train_index}, val: {val_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_scores = []\n",
    "CNN_models_to_test = [MobileNetV2, ResNet50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING FOR <function MobileNetV2 at 0x29fabaca0>\n",
      "Fold number: 1/5\n",
      "Found 76 validated image filenames belonging to 2 classes.\n",
      "Found 20 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 235ms/step - accuracy: 0.5256 - loss: 1.6556 - val_accuracy: 0.6000 - val_loss: 1.7810\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.7092 - loss: 1.1855 - val_accuracy: 0.6500 - val_loss: 0.4931\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 0.8032 - loss: 0.3744 - val_accuracy: 0.9000 - val_loss: 0.2674\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.9690 - loss: 0.1279 - val_accuracy: 0.8000 - val_loss: 0.3061\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.9235 - loss: 0.1288 - val_accuracy: 0.8500 - val_loss: 0.4212\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8375 - loss: 0.2895 \n",
      "Fold number: 2/5\n",
      "Found 77 validated image filenames belonging to 2 classes.\n",
      "Found 19 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 222ms/step - accuracy: 0.5902 - loss: 1.3221 - val_accuracy: 0.5789 - val_loss: 0.8173\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.5941 - loss: 0.8045 - val_accuracy: 0.6316 - val_loss: 1.0448\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 0.9003 - loss: 0.4025 - val_accuracy: 0.8947 - val_loss: 0.4164\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.9514 - loss: 0.1708 - val_accuracy: 0.8947 - val_loss: 0.2989\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 0.9957 - loss: 0.0756 - val_accuracy: 0.8421 - val_loss: 0.2994\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8322 - loss: 0.2934 \n",
      "Fold number: 3/5\n",
      "Found 77 validated image filenames belonging to 2 classes.\n",
      "Found 19 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - accuracy: 0.4345 - loss: 1.0419 - val_accuracy: 0.7895 - val_loss: 0.5057\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 0.9032 - loss: 0.2683 - val_accuracy: 0.8421 - val_loss: 0.4641\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.9354 - loss: 0.1724 - val_accuracy: 0.8421 - val_loss: 0.4206\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.9957 - loss: 0.1247 - val_accuracy: 0.7895 - val_loss: 0.4925\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.9455 - loss: 0.1102 - val_accuracy: 1.0000 - val_loss: 0.1915\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.1528 \n",
      "Fold number: 4/5\n",
      "Found 77 validated image filenames belonging to 2 classes.\n",
      "Found 19 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 227ms/step - accuracy: 0.4425 - loss: 0.7580 - val_accuracy: 0.7368 - val_loss: 0.3655\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.9229 - loss: 0.1660 - val_accuracy: 0.7368 - val_loss: 0.4174\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.9670 - loss: 0.0898 - val_accuracy: 0.8421 - val_loss: 0.2960\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0271 - val_accuracy: 0.8421 - val_loss: 0.2783\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0249 - val_accuracy: 0.8421 - val_loss: 0.3396\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8322 - loss: 0.2181 \n",
      "Fold number: 5/5\n",
      "Found 77 validated image filenames belonging to 2 classes.\n",
      "Found 19 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 230ms/step - accuracy: 0.5646 - loss: 0.9449 - val_accuracy: 0.7895 - val_loss: 0.4070\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.8352 - loss: 0.3344 - val_accuracy: 0.6842 - val_loss: 1.1355\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9027 - loss: 0.2173 - val_accuracy: 0.9474 - val_loss: 0.1547\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9347 - loss: 0.1573 - val_accuracy: 1.0000 - val_loss: 0.0997\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9556 - loss: 0.1098 - val_accuracy: 0.9474 - val_loss: 0.0523\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9441 - loss: 0.0552 \n",
      "TRAINING FOR <function VGG16 at 0x29faf1580>\n",
      "Fold number: 1/5\n",
      "Found 76 validated image filenames belonging to 2 classes.\n",
      "Found 20 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.3880 - loss: 0.8061 - val_accuracy: 0.5000 - val_loss: 0.7349\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.4834 - loss: 0.7256 - val_accuracy: 0.6500 - val_loss: 0.6344\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7101 - loss: 0.6011 - val_accuracy: 0.8000 - val_loss: 0.5906\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8248 - loss: 0.5403 - val_accuracy: 0.7500 - val_loss: 0.5692\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7945 - loss: 0.5122 - val_accuracy: 0.7500 - val_loss: 0.5332\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 282ms/step - accuracy: 0.7500 - loss: 0.5335\n",
      "Fold number: 2/5\n",
      "Found 77 validated image filenames belonging to 2 classes.\n",
      "Found 19 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.4068 - loss: 0.8918 - val_accuracy: 0.5789 - val_loss: 0.6982\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.6307 - loss: 0.6850 - val_accuracy: 0.5263 - val_loss: 0.5630\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.6764 - loss: 0.6351 - val_accuracy: 0.5789 - val_loss: 0.7141\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.6712 - loss: 0.6012 - val_accuracy: 0.8947 - val_loss: 0.4582\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8845 - loss: 0.5458 - val_accuracy: 0.8421 - val_loss: 0.4455\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 0.8531 - loss: 0.5469\n",
      "Fold number: 3/5\n",
      "Found 77 validated image filenames belonging to 2 classes.\n",
      "Found 19 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.5936 - loss: 0.7132 - val_accuracy: 0.5263 - val_loss: 0.5781\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.4983 - loss: 0.7777 - val_accuracy: 0.4737 - val_loss: 0.5539\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.6220 - loss: 0.6414 - val_accuracy: 0.7368 - val_loss: 0.5261\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7129 - loss: 0.5588 - val_accuracy: 0.6842 - val_loss: 0.5988\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8311 - loss: 0.4997 - val_accuracy: 0.6842 - val_loss: 0.5188\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 215ms/step - accuracy: 0.7061 - loss: 0.5864\n",
      "Fold number: 4/5\n",
      "Found 77 validated image filenames belonging to 2 classes.\n",
      "Found 19 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.5742 - loss: 0.7150 - val_accuracy: 0.6316 - val_loss: 0.6443\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.6115 - loss: 0.6418 - val_accuracy: 0.6842 - val_loss: 0.6661\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.6966 - loss: 0.5723 - val_accuracy: 0.6842 - val_loss: 0.6720\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7407 - loss: 0.5459 - val_accuracy: 0.7368 - val_loss: 0.4951\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7981 - loss: 0.4875 - val_accuracy: 0.7368 - val_loss: 0.6154\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 214ms/step - accuracy: 0.7204 - loss: 0.5318\n",
      "Fold number: 5/5\n",
      "Found 77 validated image filenames belonging to 2 classes.\n",
      "Found 19 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.5346 - loss: 0.7912 - val_accuracy: 0.4737 - val_loss: 0.5749\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.4906 - loss: 0.7339 - val_accuracy: 0.6316 - val_loss: 0.6469\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7338 - loss: 0.5780 - val_accuracy: 0.5789 - val_loss: 0.7079\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.6744 - loss: 0.5692 - val_accuracy: 0.5789 - val_loss: 0.6448\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7114 - loss: 0.5552 - val_accuracy: 0.7895 - val_loss: 0.5915\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step - accuracy: 0.7971 - loss: 0.6255\n",
      "TRAINING FOR <function ResNet50 at 0x29faf0860>\n",
      "Fold number: 1/5\n",
      "Found 76 validated image filenames belonging to 2 classes.\n",
      "Found 20 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 597ms/step - accuracy: 0.4825 - loss: 1.1164 - val_accuracy: 0.5000 - val_loss: 0.9885\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 435ms/step - accuracy: 0.4818 - loss: 0.9246 - val_accuracy: 0.5000 - val_loss: 0.7710\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 455ms/step - accuracy: 0.5645 - loss: 0.6176 - val_accuracy: 0.5000 - val_loss: 0.6865\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 436ms/step - accuracy: 0.5142 - loss: 0.7294 - val_accuracy: 0.6500 - val_loss: 0.5939\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 437ms/step - accuracy: 0.6906 - loss: 0.6689 - val_accuracy: 0.5500 - val_loss: 0.6099\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.5750 - loss: 0.6170\n",
      "Fold number: 2/5\n",
      "Found 77 validated image filenames belonging to 2 classes.\n",
      "Found 19 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 585ms/step - accuracy: 0.5048 - loss: 1.1372 - val_accuracy: 0.5263 - val_loss: 0.9244\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 434ms/step - accuracy: 0.5905 - loss: 0.8542 - val_accuracy: 0.4737 - val_loss: 0.9404\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 427ms/step - accuracy: 0.3854 - loss: 0.9593 - val_accuracy: 0.5263 - val_loss: 0.7924\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 449ms/step - accuracy: 0.5099 - loss: 0.7510 - val_accuracy: 0.4737 - val_loss: 0.6256\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 450ms/step - accuracy: 0.5177 - loss: 0.6662 - val_accuracy: 0.6842 - val_loss: 0.5913\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7061 - loss: 0.6126\n",
      "Fold number: 3/5\n",
      "Found 77 validated image filenames belonging to 2 classes.\n",
      "Found 19 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 587ms/step - accuracy: 0.4670 - loss: 1.0996 - val_accuracy: 0.5263 - val_loss: 1.0981\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 449ms/step - accuracy: 0.5197 - loss: 0.7728 - val_accuracy: 0.4737 - val_loss: 0.8819\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 440ms/step - accuracy: 0.5596 - loss: 0.7486 - val_accuracy: 0.5789 - val_loss: 0.5460\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 435ms/step - accuracy: 0.6019 - loss: 0.6180 - val_accuracy: 0.5789 - val_loss: 0.8504\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 450ms/step - accuracy: 0.6318 - loss: 0.6359 - val_accuracy: 0.5789 - val_loss: 0.4862\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5735 - loss: 0.6440\n",
      "Fold number: 4/5\n",
      "Found 77 validated image filenames belonging to 2 classes.\n",
      "Found 19 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 592ms/step - accuracy: 0.6046 - loss: 0.7277 - val_accuracy: 0.5789 - val_loss: 0.7954\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 433ms/step - accuracy: 0.5470 - loss: 0.7464 - val_accuracy: 0.5263 - val_loss: 0.6222\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 433ms/step - accuracy: 0.5559 - loss: 0.6732 - val_accuracy: 0.6842 - val_loss: 0.6454\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 431ms/step - accuracy: 0.6679 - loss: 0.6015 - val_accuracy: 0.6316 - val_loss: 0.5631\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 451ms/step - accuracy: 0.7279 - loss: 0.5883 - val_accuracy: 0.6842 - val_loss: 0.4605\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6853 - loss: 0.5261\n",
      "Fold number: 5/5\n",
      "Found 77 validated image filenames belonging to 2 classes.\n",
      "Found 19 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 590ms/step - accuracy: 0.5588 - loss: 1.0659 - val_accuracy: 0.5263 - val_loss: 0.9593\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 434ms/step - accuracy: 0.5046 - loss: 0.8212 - val_accuracy: 0.6316 - val_loss: 0.6431\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 435ms/step - accuracy: 0.5976 - loss: 0.7087 - val_accuracy: 0.5263 - val_loss: 0.5998\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 432ms/step - accuracy: 0.6011 - loss: 0.6981 - val_accuracy: 0.7368 - val_loss: 0.9237\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 436ms/step - accuracy: 0.6126 - loss: 0.6499 - val_accuracy: 0.4737 - val_loss: 1.0820\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.4616 - loss: 0.8448\n"
     ]
    }
   ],
   "source": [
    "for CNN_base_model in CNN_models_to_test:\n",
    "    fold_scores_for_CNN = []\n",
    "    fold_no = 1\n",
    "    print(f\"TRAINING FOR {CNN_base_model}\")\n",
    "    for train_index, val_index in kf.split(img_filenames_vector, labels_vector):\n",
    "        print(f\"Fold number: {fold_no}/5\")\n",
    "        train_filenames, val_filenames = img_filenames_vector[train_index], img_filenames_vector[val_index]\n",
    "        train_labels, val_labels = labels_vector[train_index], labels_vector[val_index]\n",
    "        \n",
    "        # Create ImageDataGenerator for train and validation\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "        # Create generators\n",
    "        train_generator = train_datagen.flow_from_dataframe(\n",
    "            dataframe=data_file.iloc[train_index],\n",
    "            directory=augmented_images,\n",
    "            x_col='filename',\n",
    "            y_col='label',\n",
    "            target_size=(224, 224),\n",
    "            batch_size=16,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        \n",
    "        val_generator = val_datagen.flow_from_dataframe(\n",
    "            dataframe=data_file.iloc[val_index],\n",
    "            directory=augmented_images,\n",
    "            x_col='filename',\n",
    "            y_col='label',\n",
    "            target_size=(224, 224),\n",
    "            batch_size=16,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        model = create_model(CNN_base_model)\n",
    "        history = model.fit(train_generator, validation_data=val_generator, epochs=5)\n",
    "        fold_scores_for_CNN.append(model.evaluate(val_generator))\n",
    "        fold_no += 1\n",
    "    CNN_scores.append(fold_scores_for_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1614833 0.8963158]\n",
      "[0.57276335 0.76052632]\n",
      "[0.65637482 0.59421054]\n"
     ]
    }
   ],
   "source": [
    "for score in CNN_scores:\n",
    "    print(np.mean(score, axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
