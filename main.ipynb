{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squad404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, VGG16\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Loading the augmented images and converting to pd dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv and images \n",
    "data_annotations_csv = 'resources/augmented_data/image_labels.csv'\n",
    "augmented_images = 'resources/augmented_data'\n",
    "\n",
    "data_file = pd.read_csv(data_annotations_csv, dtype={'label': str})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating vectors of filenames and labels matched by index \n",
    "img_filenames_vector = data_file['filename'].values\n",
    "labels_vector = data_file['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our model\n",
    "\n",
    "Add prototypical network to our model before running it through the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a model from the pretrained CNN base you pass in\n",
    "# Example usage: model = create_model(MobileNetv2)\n",
    "def create_model(base):\n",
    "    base_model = base(input_shape=(224, 224, 3), include_top=False)\n",
    "    base_model.trainable = False # Freeze the base_model\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [  0   1   2   3   4   6   7   8   9  10  11  12  13  14  16  17  18  20\n",
      "  21  23  24  25  27  28  31  32  33  34  35  36  38  39  40  41  42  44\n",
      "  45  48  49  51  52  53  54  55  56  57  58  59  60  61  63  65  66  67\n",
      "  68  69  70  72  74  76  77  78  79  80  83  84  85  87  88  89  90  91\n",
      "  92  93  94  95  97  98  99 101 102 103 104 105 106 107 108 110 111 112\n",
      " 113 114 115 116 117 118 119 120 121 122 123 125 126 127 128 129 131 132\n",
      " 133 134 135 137 139 140 141 144 145 146 148 149 152 153 154 155 156 157\n",
      " 158 159], val: [  5  15  19  22  26  29  30  37  43  46  47  50  62  64  71  73  75  81\n",
      "  82  86  96 100 109 124 130 136 138 142 143 147 150 151]\n",
      "train: [  0   2   4   5   6   7   8   9  10  11  12  13  15  16  17  18  19  20\n",
      "  22  23  24  25  26  27  29  30  31  32  33  35  37  39  41  42  43  44\n",
      "  45  46  47  48  49  50  51  52  53  54  55  56  60  61  62  63  64  65\n",
      "  66  67  69  70  71  73  75  77  78  79  81  82  83  84  86  87  88  89\n",
      "  90  91  96  97  99 100 101 102 103 104 105 107 108 109 111 112 114 115\n",
      " 116 117 118 120 121 122 123 124 126 127 128 129 130 131 132 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 146 147 148 149 150 151 152 154 155\n",
      " 156 159], val: [  1   3  14  21  28  34  36  38  40  57  58  59  68  72  74  76  80  85\n",
      "  92  93  94  95  98 106 110 113 119 125 145 153 157 158]\n",
      "train: [  1   2   3   4   5   7   9  10  11  12  13  14  15  17  18  19  20  21\n",
      "  22  23  24  26  28  29  30  31  32  33  34  35  36  37  38  39  40  42\n",
      "  43  44  45  46  47  49  50  51  52  53  54  55  57  58  59  60  62  63\n",
      "  64  66  68  69  70  71  72  73  74  75  76  77  79  80  81  82  83  85\n",
      "  86  87  89  90  92  93  94  95  96  97  98 100 101 102 103 106 108 109\n",
      " 110 112 113 114 116 117 118 119 121 123 124 125 126 127 128 130 135 136\n",
      " 138 139 140 142 143 144 145 146 147 148 149 150 151 153 154 155 156 157\n",
      " 158 159], val: [  0   6   8  16  25  27  41  48  56  61  65  67  78  84  88  91  99 104\n",
      " 105 107 111 115 120 122 129 131 132 133 134 137 141 152]\n",
      "train: [  0   1   3   4   5   6   7   8   9  10  12  14  15  16  19  20  21  22\n",
      "  24  25  26  27  28  29  30  31  32  34  36  37  38  40  41  43  44  45\n",
      "  46  47  48  50  55  56  57  58  59  60  61  62  63  64  65  66  67  68\n",
      "  70  71  72  73  74  75  76  77  78  80  81  82  84  85  86  87  88  91\n",
      "  92  93  94  95  96  98  99 100 102 103 104 105 106 107 108 109 110 111\n",
      " 112 113 114 115 118 119 120 121 122 123 124 125 126 129 130 131 132 133\n",
      " 134 136 137 138 140 141 142 143 144 145 147 148 150 151 152 153 154 157\n",
      " 158 159], val: [  2  11  13  17  18  23  33  35  39  42  49  51  52  53  54  69  79  83\n",
      "  89  90  97 101 116 117 127 128 135 139 146 149 155 156]\n",
      "train: [  0   1   2   3   5   6   8  11  13  14  15  16  17  18  19  21  22  23\n",
      "  25  26  27  28  29  30  33  34  35  36  37  38  39  40  41  42  43  46\n",
      "  47  48  49  50  51  52  53  54  56  57  58  59  61  62  64  65  67  68\n",
      "  69  71  72  73  74  75  76  78  79  80  81  82  83  84  85  86  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 104 105 106 107 109 110\n",
      " 111 113 115 116 117 119 120 122 124 125 127 128 129 130 131 132 133 134\n",
      " 135 136 137 138 139 141 142 143 145 146 147 149 150 151 152 153 155 156\n",
      " 157 158], val: [  4   7   9  10  12  20  24  31  32  44  45  55  60  63  66  70  77  87\n",
      " 102 103 108 112 114 118 121 123 126 140 144 148 154 159]\n"
     ]
    }
   ],
   "source": [
    "for train_index, val_index in kf.split(img_filenames_vector, labels_vector):\n",
    "    print(f\"train: {train_index}, val: {val_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_scores = []\n",
    "CNN_models_to_test = [MobileNetV2, ResNet50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING FOR <function MobileNetV2 at 0x30da8fce0>\n",
      "Fold number: 1/5\n",
      "Found 128 validated image filenames belonging to 2 classes.\n",
      "Found 32 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/george/Documents/Dev/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 190ms/step - accuracy: 0.5425 - loss: 1.4929 - val_accuracy: 0.8125 - val_loss: 0.3889\n",
      "Epoch 2/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.7074 - loss: 0.6151 - val_accuracy: 0.8750 - val_loss: 0.2888\n",
      "Epoch 3/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.8817 - loss: 0.2435 - val_accuracy: 1.0000 - val_loss: 0.0842\n",
      "Epoch 4/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0779 - val_accuracy: 1.0000 - val_loss: 0.0574\n",
      "Epoch 5/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0369 - val_accuracy: 1.0000 - val_loss: 0.0411\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 0.0418\n",
      "Fold number: 2/5\n",
      "Found 128 validated image filenames belonging to 2 classes.\n",
      "Found 32 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/george/Documents/Dev/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 194ms/step - accuracy: 0.6350 - loss: 0.7876 - val_accuracy: 0.9375 - val_loss: 0.2402\n",
      "Epoch 2/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.9198 - loss: 0.1696 - val_accuracy: 0.8438 - val_loss: 0.2105\n",
      "Epoch 3/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.9477 - loss: 0.1021 - val_accuracy: 0.9688 - val_loss: 0.1210\n",
      "Epoch 4/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 1.0000 - val_loss: 0.0194\n",
      "Epoch 5/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 0.0091\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.0092\n",
      "Fold number: 3/5\n",
      "Found 128 validated image filenames belonging to 2 classes.\n",
      "Found 32 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/george/Documents/Dev/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 190ms/step - accuracy: 0.6161 - loss: 1.2506 - val_accuracy: 0.5312 - val_loss: 0.8616\n",
      "Epoch 2/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.8349 - loss: 0.3586 - val_accuracy: 0.7500 - val_loss: 0.4513\n",
      "Epoch 3/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.8729 - loss: 0.2813 - val_accuracy: 0.9062 - val_loss: 0.1783\n",
      "Epoch 4/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9675 - loss: 0.0758 - val_accuracy: 1.0000 - val_loss: 0.0392\n",
      "Epoch 5/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.9930 - loss: 0.0205 - val_accuracy: 1.0000 - val_loss: 0.0304\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.0367\n",
      "Fold number: 4/5\n",
      "Found 128 validated image filenames belonging to 2 classes.\n",
      "Found 32 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/george/Documents/Dev/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 197ms/step - accuracy: 0.5460 - loss: 0.8338 - val_accuracy: 0.9688 - val_loss: 0.1697\n",
      "Epoch 2/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.9192 - loss: 0.1929 - val_accuracy: 0.9375 - val_loss: 0.1330\n",
      "Epoch 3/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.9907 - loss: 0.0516 - val_accuracy: 1.0000 - val_loss: 0.0447\n",
      "Epoch 4/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0370 - val_accuracy: 1.0000 - val_loss: 0.0101\n",
      "Epoch 5/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 1.0000 - val_loss: 0.0173\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.0168\n",
      "Fold number: 5/5\n",
      "Found 128 validated image filenames belonging to 2 classes.\n",
      "Found 32 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/george/Documents/Dev/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 190ms/step - accuracy: 0.5266 - loss: 0.8379 - val_accuracy: 0.7188 - val_loss: 0.5610\n",
      "Epoch 2/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9685 - loss: 0.1224 - val_accuracy: 0.7812 - val_loss: 0.3629\n",
      "Epoch 3/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.9534 - loss: 0.1118 - val_accuracy: 0.9062 - val_loss: 0.2848\n",
      "Epoch 4/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.9930 - loss: 0.0271 - val_accuracy: 0.9375 - val_loss: 0.2614\n",
      "Epoch 5/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.9688 - val_loss: 0.1189\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.9792 - loss: 0.1011\n",
      "TRAINING FOR <function ResNet50 at 0x30dab1bc0>\n",
      "Fold number: 1/5\n",
      "Found 128 validated image filenames belonging to 2 classes.\n",
      "Found 32 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/george/Documents/Dev/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 623ms/step - accuracy: 0.5605 - loss: 1.1773 - val_accuracy: 0.5000 - val_loss: 0.8339\n",
      "Epoch 2/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 540ms/step - accuracy: 0.4564 - loss: 0.9329 - val_accuracy: 0.5000 - val_loss: 0.9961\n",
      "Epoch 3/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 560ms/step - accuracy: 0.5074 - loss: 0.8869 - val_accuracy: 0.5000 - val_loss: 0.8930\n",
      "Epoch 4/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 572ms/step - accuracy: 0.6519 - loss: 0.6679 - val_accuracy: 0.5000 - val_loss: 0.9834\n",
      "Epoch 5/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 557ms/step - accuracy: 0.4632 - loss: 0.8947 - val_accuracy: 0.5000 - val_loss: 0.7555\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step - accuracy: 0.5208 - loss: 0.7372\n",
      "Fold number: 2/5\n",
      "Found 128 validated image filenames belonging to 2 classes.\n",
      "Found 32 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/george/Documents/Dev/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 641ms/step - accuracy: 0.4941 - loss: 1.1352 - val_accuracy: 0.5000 - val_loss: 0.6965\n",
      "Epoch 2/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 558ms/step - accuracy: 0.3608 - loss: 1.1008 - val_accuracy: 0.5000 - val_loss: 0.8873\n",
      "Epoch 3/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 568ms/step - accuracy: 0.5075 - loss: 0.8145 - val_accuracy: 0.5000 - val_loss: 0.7757\n",
      "Epoch 4/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 569ms/step - accuracy: 0.4894 - loss: 0.7116 - val_accuracy: 0.5000 - val_loss: 0.7108\n",
      "Epoch 5/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 575ms/step - accuracy: 0.5149 - loss: 0.6804 - val_accuracy: 0.4375 - val_loss: 0.7077\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step - accuracy: 0.4167 - loss: 0.7107\n",
      "Fold number: 3/5\n",
      "Found 128 validated image filenames belonging to 2 classes.\n",
      "Found 32 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/george/Documents/Dev/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 664ms/step - accuracy: 0.5129 - loss: 1.3299 - val_accuracy: 0.5000 - val_loss: 0.6726\n",
      "Epoch 2/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 565ms/step - accuracy: 0.5240 - loss: 1.0399 - val_accuracy: 0.5000 - val_loss: 0.8822\n",
      "Epoch 3/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 570ms/step - accuracy: 0.5531 - loss: 0.8728 - val_accuracy: 0.5000 - val_loss: 0.9533\n",
      "Epoch 4/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 573ms/step - accuracy: 0.4234 - loss: 0.9833 - val_accuracy: 0.5000 - val_loss: 0.7122\n",
      "Epoch 5/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 594ms/step - accuracy: 0.6534 - loss: 0.6148 - val_accuracy: 0.5625 - val_loss: 0.6916\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 446ms/step - accuracy: 0.5625 - loss: 0.6818\n",
      "Fold number: 4/5\n",
      "Found 128 validated image filenames belonging to 2 classes.\n",
      "Found 32 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/george/Documents/Dev/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 660ms/step - accuracy: 0.4926 - loss: 1.0881 - val_accuracy: 0.5000 - val_loss: 0.7877\n",
      "Epoch 2/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 579ms/step - accuracy: 0.5623 - loss: 0.8944 - val_accuracy: 0.5000 - val_loss: 1.1497\n",
      "Epoch 3/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 580ms/step - accuracy: 0.4741 - loss: 0.9906 - val_accuracy: 0.5000 - val_loss: 0.6855\n",
      "Epoch 4/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 584ms/step - accuracy: 0.5810 - loss: 0.6902 - val_accuracy: 0.7500 - val_loss: 0.6381\n",
      "Epoch 5/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 597ms/step - accuracy: 0.5499 - loss: 0.8038 - val_accuracy: 0.5000 - val_loss: 0.8432\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474ms/step - accuracy: 0.5417 - loss: 0.7821\n",
      "Fold number: 5/5\n",
      "Found 128 validated image filenames belonging to 2 classes.\n",
      "Found 32 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/george/Documents/Dev/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 687ms/step - accuracy: 0.4636 - loss: 1.2493 - val_accuracy: 0.5000 - val_loss: 0.9965\n",
      "Epoch 2/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 594ms/step - accuracy: 0.4607 - loss: 0.9064 - val_accuracy: 0.5312 - val_loss: 0.6929\n",
      "Epoch 3/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 588ms/step - accuracy: 0.6018 - loss: 0.6579 - val_accuracy: 0.5000 - val_loss: 0.6960\n",
      "Epoch 4/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 586ms/step - accuracy: 0.5742 - loss: 0.6691 - val_accuracy: 0.5000 - val_loss: 0.6864\n",
      "Epoch 5/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 601ms/step - accuracy: 0.5550 - loss: 0.6473 - val_accuracy: 0.5312 - val_loss: 0.7883\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450ms/step - accuracy: 0.6042 - loss: 0.7179\n"
     ]
    }
   ],
   "source": [
    "for CNN_base_model in CNN_models_to_test:\n",
    "    fold_scores_for_CNN = []\n",
    "    fold_no = 1\n",
    "    print(f\"TRAINING FOR {CNN_base_model}\")\n",
    "    for train_index, val_index in kf.split(img_filenames_vector, labels_vector):\n",
    "        print(f\"Fold number: {fold_no}/5\")\n",
    "        train_filenames, val_filenames = img_filenames_vector[train_index], img_filenames_vector[val_index]\n",
    "        train_labels, val_labels = labels_vector[train_index], labels_vector[val_index]\n",
    "        \n",
    "        # Create ImageDataGenerator for train and validation\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "        # Create generators\n",
    "        train_generator = train_datagen.flow_from_dataframe(\n",
    "            dataframe=data_file.iloc[train_index],\n",
    "            directory=augmented_images,\n",
    "            x_col='filename',\n",
    "            y_col='label',\n",
    "            target_size=(224, 224),\n",
    "            batch_size=16,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        \n",
    "        val_generator = val_datagen.flow_from_dataframe(\n",
    "            dataframe=data_file.iloc[val_index],\n",
    "            directory=augmented_images,\n",
    "            x_col='filename',\n",
    "            y_col='label',\n",
    "            target_size=(224, 224),\n",
    "            batch_size=16,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        model = create_model(CNN_base_model)\n",
    "        history = model.fit(train_generator, validation_data=val_generator, epochs=5)\n",
    "        fold_scores_for_CNN.append(model.evaluate(val_generator))\n",
    "        fold_no += 1\n",
    "    CNN_scores.append(fold_scores_for_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04338196 0.99375   ]\n",
      "[0.7572655 0.50625  ]\n"
     ]
    }
   ],
   "source": [
    "for score in CNN_scores:\n",
    "    print(np.mean(score, axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
