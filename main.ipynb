{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squad404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, VGG16\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Loading the augmented images and converting to pd dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv and images \n",
    "data_annotations_csv = 'Data - Needs Respray - 2024-03-26/Labels-NeedsRespray-2024-03-26.csv'\n",
    "augmented_images = 'Data - Needs Respray - 2024-03-26'\n",
    "\n",
    "data_file = pd.read_csv(data_annotations_csv, dtype={'label': str})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Filename Needs Respray\n",
      "0   paver weeds - 03.png           Yes\n",
      "1   paver weeds - 09.png           Yes\n",
      "2   paver weeds - 17.png           Yes\n",
      "3   paver weeds - 25.png            No\n",
      "4   paver weeds - 32.png            No\n",
      "5   paver weeds - 36.png            No\n",
      "6   paver weeds - 43.png            No\n",
      "7   paver weeds - 47.png            No\n",
      "8   paver weeds - 59.png            No\n",
      "9   paver weeds - 63.png           Yes\n",
      "10  paver weeds - 77.png           Yes\n",
      "11  paver weeds - 85.png           Yes\n"
     ]
    }
   ],
   "source": [
    "print(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating vectors of filenames and labels matched by index \n",
    "img_filenames_vector = data_file['Filename'].values\n",
    "labels_vector = data_file['Needs Respray'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our model\n",
    "\n",
    "Add prototypical network to our model before running it through the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a model from the pretrained CNN base you pass in\n",
    "# Example usage: model = create_model(MobileNetv2)\n",
    "def create_model(base):\n",
    "    base_model = base(input_shape=(224, 224, 3), include_top=False)\n",
    "    base_model.trainable = False # Freeze the base_model\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [ 0  1  2  3  4  5  6  7 11], val: [ 8  9 10]\n",
      "train: [ 0  1  4  5  6  8  9 10 11], val: [2 3 7]\n",
      "train: [ 1  2  3  4  5  7  8  9 10 11], val: [0 6]\n",
      "train: [ 0  2  3  5  6  7  8  9 10 11], val: [1 4]\n",
      "train: [ 0  1  2  3  4  6  7  8  9 10], val: [ 5 11]\n"
     ]
    }
   ],
   "source": [
    "for train_index, val_index in kf.split(img_filenames_vector, labels_vector):\n",
    "    print(f\"train: {train_index}, val: {val_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_scores = []\n",
    "CNN_models_to_test = [MobileNetV2, ResNet50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING FOR <function MobileNetV2 at 0x2a0288860>\n",
      "Fold number: 1/5\n",
      "Found 9 validated image filenames belonging to 2 classes.\n",
      "Found 3 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4444 - loss: 0.7442 - val_accuracy: 0.3333 - val_loss: 2.5632\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step - accuracy: 0.8889 - loss: 0.2567 - val_accuracy: 0.3333 - val_loss: 2.3856\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564ms/step - accuracy: 1.0000 - loss: 0.0419 - val_accuracy: 0.3333 - val_loss: 2.1931\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step - accuracy: 1.0000 - loss: 0.0257 - val_accuracy: 0.6667 - val_loss: 2.1819\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.6667 - val_loss: 2.2429\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.6667 - loss: 2.2429\n",
      "Fold number: 2/5\n",
      "Found 9 validated image filenames belonging to 2 classes.\n",
      "Found 3 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.3333 - loss: 0.8059 - val_accuracy: 0.3333 - val_loss: 1.6115\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step - accuracy: 1.0000 - loss: 0.2427 - val_accuracy: 0.6667 - val_loss: 1.5103\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557ms/step - accuracy: 0.8889 - loss: 0.1725 - val_accuracy: 0.6667 - val_loss: 2.0051\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step - accuracy: 1.0000 - loss: 0.0607 - val_accuracy: 0.6667 - val_loss: 2.5895\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 0.6667 - val_loss: 3.1265\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.6667 - loss: 3.1265\n",
      "Fold number: 3/5\n",
      "Found 10 validated image filenames belonging to 2 classes.\n",
      "Found 2 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 0.7691 - val_accuracy: 0.5000 - val_loss: 1.8483\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step - accuracy: 0.5000 - loss: 1.2828 - val_accuracy: 0.5000 - val_loss: 0.5559\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564ms/step - accuracy: 1.0000 - loss: 0.1705 - val_accuracy: 1.0000 - val_loss: 0.3632\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step - accuracy: 0.9000 - loss: 0.2573 - val_accuracy: 0.5000 - val_loss: 0.6339\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564ms/step - accuracy: 0.9000 - loss: 0.3251 - val_accuracy: 0.5000 - val_loss: 0.5946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5000 - loss: 0.5946\n",
      "Fold number: 4/5\n",
      "Found 10 validated image filenames belonging to 2 classes.\n",
      "Found 2 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.4000 - loss: 0.6688 - val_accuracy: 0.5000 - val_loss: 0.4836\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step - accuracy: 0.9000 - loss: 0.3474 - val_accuracy: 1.0000 - val_loss: 0.3241\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step - accuracy: 1.0000 - loss: 0.1151 - val_accuracy: 0.5000 - val_loss: 0.4286\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step - accuracy: 1.0000 - loss: 0.1043 - val_accuracy: 1.0000 - val_loss: 0.2070\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559ms/step - accuracy: 1.0000 - loss: 0.0305 - val_accuracy: 1.0000 - val_loss: 0.0892\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 0.0892\n",
      "Fold number: 5/5\n",
      "Found 10 validated image filenames belonging to 2 classes.\n",
      "Found 2 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4000 - loss: 0.7634 - val_accuracy: 0.5000 - val_loss: 0.5955\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step - accuracy: 0.9000 - loss: 0.2742 - val_accuracy: 0.5000 - val_loss: 0.5931\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step - accuracy: 1.0000 - loss: 0.0943 - val_accuracy: 0.5000 - val_loss: 0.7052\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step - accuracy: 1.0000 - loss: 0.0212 - val_accuracy: 0.5000 - val_loss: 1.0310\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.5000 - val_loss: 1.4203\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.5000 - loss: 1.4203\n",
      "TRAINING FOR <function ResNet50 at 0x2a028a3e0>\n",
      "Fold number: 1/5\n",
      "Found 9 validated image filenames belonging to 2 classes.\n",
      "Found 3 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.6667 - loss: 0.6697 - val_accuracy: 0.3333 - val_loss: 1.3621\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760ms/step - accuracy: 0.5556 - loss: 0.9291 - val_accuracy: 1.0000 - val_loss: 0.3520\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754ms/step - accuracy: 0.4444 - loss: 0.7121 - val_accuracy: 1.0000 - val_loss: 0.3147\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 756ms/step - accuracy: 0.4444 - loss: 0.7364 - val_accuracy: 0.6667 - val_loss: 0.4474\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755ms/step - accuracy: 0.7778 - loss: 0.5358 - val_accuracy: 0.3333 - val_loss: 0.8411\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.3333 - loss: 0.8411\n",
      "Fold number: 2/5\n",
      "Found 9 validated image filenames belonging to 2 classes.\n",
      "Found 3 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5556 - loss: 0.7402 - val_accuracy: 0.6667 - val_loss: 1.1600\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755ms/step - accuracy: 0.4444 - loss: 1.8353 - val_accuracy: 0.6667 - val_loss: 0.6243\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755ms/step - accuracy: 0.4444 - loss: 0.7841 - val_accuracy: 0.3333 - val_loss: 1.1131\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 756ms/step - accuracy: 0.5556 - loss: 0.8456 - val_accuracy: 0.3333 - val_loss: 1.5255\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755ms/step - accuracy: 0.5556 - loss: 1.1246 - val_accuracy: 0.3333 - val_loss: 1.2620\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.3333 - loss: 1.2620\n",
      "Fold number: 3/5\n",
      "Found 10 validated image filenames belonging to 2 classes.\n",
      "Found 2 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.5000 - loss: 0.8953 - val_accuracy: 0.5000 - val_loss: 1.5667\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762ms/step - accuracy: 0.5000 - loss: 1.5430 - val_accuracy: 0.5000 - val_loss: 1.0192\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758ms/step - accuracy: 0.5000 - loss: 0.9832 - val_accuracy: 0.5000 - val_loss: 0.6951\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762ms/step - accuracy: 0.9000 - loss: 0.5845 - val_accuracy: 0.5000 - val_loss: 1.0684\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 756ms/step - accuracy: 0.5000 - loss: 0.8611 - val_accuracy: 0.5000 - val_loss: 1.1171\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.5000 - loss: 1.1171\n",
      "Fold number: 4/5\n",
      "Found 10 validated image filenames belonging to 2 classes.\n",
      "Found 2 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5000 - loss: 0.7128 - val_accuracy: 0.5000 - val_loss: 1.4612\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761ms/step - accuracy: 0.5000 - loss: 1.5271 - val_accuracy: 1.0000 - val_loss: 0.4661\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765ms/step - accuracy: 0.8000 - loss: 0.5984 - val_accuracy: 0.5000 - val_loss: 0.9317\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769ms/step - accuracy: 0.5000 - loss: 1.1295 - val_accuracy: 0.5000 - val_loss: 0.8111\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763ms/step - accuracy: 0.5000 - loss: 1.0350 - val_accuracy: 1.0000 - val_loss: 0.4032\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.4032\n",
      "Fold number: 5/5\n",
      "Found 10 validated image filenames belonging to 2 classes.\n",
      "Found 2 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukewang/Documents/COMP9417/Squad404/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.5000 - loss: 0.8937 - val_accuracy: 0.5000 - val_loss: 1.6799\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 773ms/step - accuracy: 0.5000 - loss: 1.7154 - val_accuracy: 0.5000 - val_loss: 1.1335\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772ms/step - accuracy: 0.5000 - loss: 0.9439 - val_accuracy: 0.5000 - val_loss: 0.7245\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 771ms/step - accuracy: 0.5000 - loss: 0.6317 - val_accuracy: 0.5000 - val_loss: 0.9253\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 778ms/step - accuracy: 0.5000 - loss: 0.9444 - val_accuracy: 0.5000 - val_loss: 0.8275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.5000 - loss: 0.8275\n"
     ]
    }
   ],
   "source": [
    "for CNN_base_model in CNN_models_to_test:\n",
    "    fold_scores_for_CNN = []\n",
    "    fold_no = 1\n",
    "    print(f\"TRAINING FOR {CNN_base_model}\")\n",
    "    for train_index, val_index in kf.split(img_filenames_vector, labels_vector):\n",
    "        print(f\"Fold number: {fold_no}/5\")\n",
    "        train_filenames, val_filenames = img_filenames_vector[train_index], img_filenames_vector[val_index]\n",
    "        train_labels, val_labels = labels_vector[train_index], labels_vector[val_index]\n",
    "        \n",
    "        # Create ImageDataGenerator for train and validation\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "        # Create generators\n",
    "        train_generator = train_datagen.flow_from_dataframe(\n",
    "            dataframe=data_file.iloc[train_index],\n",
    "            directory=augmented_images,\n",
    "            x_col='Filename',\n",
    "            y_col='Needs Respray',\n",
    "            target_size=(224, 224),\n",
    "            batch_size=16,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        \n",
    "        val_generator = val_datagen.flow_from_dataframe(\n",
    "            dataframe=data_file.iloc[val_index],\n",
    "            directory=augmented_images,\n",
    "            x_col='Filename',\n",
    "            y_col='Needs Respray',\n",
    "            target_size=(224, 224),\n",
    "            batch_size=16,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        model = create_model(CNN_base_model)\n",
    "        history = model.fit(train_generator, validation_data=val_generator, epochs=5)\n",
    "        fold_scores_for_CNN.append(model.evaluate(val_generator))\n",
    "        fold_no += 1\n",
    "    CNN_scores.append(fold_scores_for_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04338196 0.99375   ]\n",
      "[0.7572655 0.50625  ]\n"
     ]
    }
   ],
   "source": [
    "for score in CNN_scores:\n",
    "    print(np.mean(score, axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
